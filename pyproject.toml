[tool.poetry]
name = "llama-factory"
version = "0.1.0"
description = "A description of your project"
authors = ["Your Name <your.email@example.com>"]
readme = "README.md"
license = "MIT"
packages = [{include = "llamafactory"}]

[tool.poetry.dependencies]
python = ">=3.10,<3.12"

# Dependencies with version ranges
transformers = ">=4.41.2,<4.44.0"
datasets = ">=2.16.0,<2.21.0"
accelerate = ">=0.30.1,<0.33.0"
peft = ">=0.11.1,<0.13.0"
trl = ">=0.8.6,<0.10.0"
gradio = ">=4.0.0"
pandas = ">=2.0.0"
matplotlib = ">=3.7.0"

# Dependencies with no explicit version range
scipy = "*"
einops = "*"
sentencepiece = "*"
tiktoken = "*"
protobuf = "*"
uvicorn = "*"
pydantic = "*"
fastapi = "*"
sse-starlette = "*"
fire = "*"
packaging = "*"
pyyaml = "*"
numpy = "^2.1.3"
liger-kernel = "^0.4.2"
flash-attn = "2.7.0.post2"

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.ruff]
target-version = "py38"
line-length = 119
indent-width = 4

[tool.ruff.lint]
ignore = ["C408", "C901", "E501", "E731", "E741", "W605"]
select = ["C", "E", "F", "I", "W"]

[tool.ruff.lint.isort]
lines-after-imports = 2
known-first-party = ["llamafactory"]
known-third-party = [
    "accelerate",
    "datasets",
    "gradio",
    "numpy",
    "peft",
    "torch",
    "transformers",
    "trl"
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
docstring-code-format = true
skip-magic-trailing-comma = false
line-ending = "auto"
